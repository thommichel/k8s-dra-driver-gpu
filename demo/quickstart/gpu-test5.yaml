# One pod, 4 containers
# Run as deployment with 1 replica

# NOTE: This demo requires 2 GPU without MIG enabled

---
apiVersion: v1
kind: Namespace
metadata:
  name: gpu-test5

---
apiVersion: resource.k8s.io/v1alpha3
kind: ResourceClaimTemplate
metadata:
  namespace: gpu-test5
  name: multiple-gpus
spec:
  spec:
    devices:
      requests:
      - name: ts-gpu
        deviceClassName: gpu.nvidia.com
      - name: mps-gpu
        deviceClassName: gpu.nvidia.com
      config:
      - requests: ["ts-gpu"]
        opaque:
          driver: gpu.nvidia.com
          parameters:
            apiVersion: gpu.nvidia.com/v1alpha1
            kind: GpuConfig
            sharing:
              strategy: TimeSlicing
              timeSlicingConfig:
                interval: Long
      - requests: ["mps-gpu"]
        opaque:
          driver: gpu.nvidia.com
          parameters:
            apiVersion: gpu.nvidia.com/v1alpha1
            kind: GpuConfig
            sharing:
              strategy: MPS
              mpsConfig:
                defaultActiveThreadPercentage: 50
                defaultPinnedDeviceMemoryLimit: 10Gi

---
apiVersion: v1
kind: Pod
metadata:
  namespace: gpu-test5
  name: pod0
spec:
  containers:
  - name: ts-ctr0
    image: nvcr.io/nvidia/k8s/cuda-sample:nbody-cuda11.6.0-ubuntu18.04
    command: ["bash", "-c"]
    args: ["trap 'exit 0' TERM; /tmp/sample --benchmark --numbodies=4226000 & wait"]
    resources:
      claims:
      - name: shared-gpus
        request: ts-gpu
    env:
    - name: NVIDIA_VISIBLE_DEVICES
      value: void
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      capabilities:
        drop:
          - ALL
  - name: ts-ctr1
    image: nvcr.io/nvidia/k8s/cuda-sample:nbody-cuda11.6.0-ubuntu18.04
    command: ["bash", "-c"]
    args: ["trap 'exit 0' TERM; /tmp/sample --benchmark --numbodies=4226000 & wait"]
    resources:
      claims:
      - name: shared-gpus
        request: ts-gpu
    env:
    - name: NVIDIA_VISIBLE_DEVICES
      value: void
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      capabilities:
        drop:
          - ALL
  - name: mps-ctr0
    image: nvcr.io/nvidia/k8s/cuda-sample:nbody-cuda11.6.0-ubuntu18.04
    command: ["bash", "-c"]
    args: ["trap 'exit 0' TERM; /tmp/sample --benchmark --numbodies=4226000 & wait"]
    resources:
      claims:
      - name: shared-gpus
        request: mps-gpu
    env:
    - name: NVIDIA_VISIBLE_DEVICES
      value: void
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      capabilities:
        drop:
          - ALL
  - name: mps-ctr1
    image: nvcr.io/nvidia/k8s/cuda-sample:nbody-cuda11.6.0-ubuntu18.04
    command: ["bash", "-c"]
    args: ["trap 'exit 0' TERM; /tmp/sample --benchmark --numbodies=4226000 & wait"]
    resources:
      claims:
      - name: shared-gpus
        request: mps-gpu
    env:
    - name: NVIDIA_VISIBLE_DEVICES
      value: void
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      capabilities:
        drop:
          - ALL
  resourceClaims:
  - name: shared-gpus
    resourceClaimTemplateName: multiple-gpus
  tolerations:
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"
