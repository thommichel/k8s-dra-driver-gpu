# One pod, two containers
# Each asking for shared access to a single GPU

# NOTE: This demo requires 1 GPU without MIG enabled

---
apiVersion: v1
kind: Namespace
metadata:
  name: gpu-test2

---
apiVersion: resource.k8s.io/v1alpha3
kind: ResourceClaimTemplate
metadata:
  namespace: gpu-test2
  name: single-gpu
spec:
  spec:
    devices:
      requests:
      - name: gpu
        deviceClassName: gpu.nvidia.com

---
apiVersion: v1
kind: Pod
metadata:
  namespace: gpu-test2
  name: pod
spec:
  containers:
  - name: ctr0
    image: nvcr.io/nvidia/k8s/cuda-sample:nbody-cuda11.6.0-ubuntu18.04
    command: ["bash", "-c"]
    args: ["trap 'exit 0' TERM; /tmp/sample --benchmark --numbodies=4226048 & wait"]
    resources:
      claims:
      - name: shared-gpu
    env:
    - name: NVIDIA_VISIBLE_DEVICES
      value: void
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      capabilities:
        drop:
          - ALL
  - name: ctr1
    image: nvcr.io/nvidia/k8s/cuda-sample:nbody-cuda11.6.0-ubuntu18.04
    command: ["bash", "-c"]
    args: ["trap 'exit 0' TERM; /tmp/sample --benchmark --numbodies=4226048 & wait"]
    resources:
      claims:
      - name: shared-gpu
    env:
    - name: NVIDIA_VISIBLE_DEVICES
      value: void
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      capabilities:
        drop:
          - ALL
  resourceClaims:
  - name: shared-gpu
    resourceClaimTemplateName: single-gpu
  tolerations:
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"
