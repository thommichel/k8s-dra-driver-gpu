# One pod, 2 containers share GPU using MPS

# NOTE: This demo requires 1 GPU without MIG enabled

---
apiVersion: v1
kind: Namespace
metadata:
  name: gpu-test-mps
---
apiVersion: resource.k8s.io/v1alpha3
kind: ResourceClaimTemplate
metadata:
  namespace: gpu-test-mps
  name: shared-gpu
spec:
  spec:
    devices:
      requests:
      - name: mps-gpu
        deviceClassName: gpu.nvidia.com
      config:
      - requests: ["mps-gpu"]
        opaque:
          driver: gpu.nvidia.com
          parameters:
            apiVersion: gpu.nvidia.com/v1alpha1
            kind: GpuConfig
            sharing:
              strategy: MPS
---
apiVersion: v1
kind: Pod
metadata:
  namespace: gpu-test-mps
  name: test-pod
  labels:
    app: pod
spec:
  containers:
  - name: mps-ctr0
    image: nvcr.io/nvidia/k8s/cuda-sample:nbody-cuda11.6.0-ubuntu18.04
    command: ["bash", "-c"]
    args: ["trap 'exit 0' TERM; /tmp/sample --benchmark --numbodies=4226048 & wait"]
    env:
    - name: NVIDIA_VISIBLE_DEVICES
      value: void
    resources:
      claims:
      - name: shared-gpu
        request: mps-gpu
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      capabilities:
        drop:
          - ALL
  - name: mps-ctr1
    image: nvcr.io/nvidia/k8s/cuda-sample:nbody-cuda11.6.0-ubuntu18.04
    command: ["bash", "-c"]
    args: ["trap 'exit 0' TERM; /tmp/sample --benchmark --numbodies=4226048 & wait"]
    env:
    - name: NVIDIA_VISIBLE_DEVICES
      value: void
    resources:
      claims:
      - name: shared-gpu
        request: mps-gpu
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      capabilities:
        drop:
          - ALL
  resourceClaims:
  - name: shared-gpu
    resourceClaimTemplateName: shared-gpu
  tolerations:
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"
